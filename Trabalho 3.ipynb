{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "import sklearn as sk\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processamento dos dados\n",
    "**Carregando os dados de treino e teste:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = pd.read_csv('../fashion-mnist_train.csv')\n",
    "test_images = pd.read_csv('../fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separando as labels do conjuntos:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=train_images.loc[:, ['label']]\n",
    "train_images=train_images.drop(['label'], axis=1)\n",
    "test_labels=test_images.loc[:, ['label']]\n",
    "test_images=test_images.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalizando os data-sets:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "## Construção do modelo base\n",
    "**Esta rede será utilizada posteriomente para comparações entre os modelos de dimensionalidade reduzida utilizando PCA e autoencoder.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definição da estrutura do modelo por meio do Keras Sequential:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 59,850\n",
      "Trainable params: 59,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64,activation=tf.nn.relu,input_dim=(784)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compilação do modelo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Treino do modelo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 0.5209 - accuracy: 0.8152 - val_loss: 0.4132 - val_accuracy: 0.8530\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 0.3867 - accuracy: 0.8570 - val_loss: 0.3680 - val_accuracy: 0.8652\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 6s 116us/sample - loss: 0.3508 - accuracy: 0.8719 - val_loss: 0.3848 - val_accuracy: 0.8627\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 5s 98us/sample - loss: 0.3276 - accuracy: 0.8792 - val_loss: 0.3647 - val_accuracy: 0.8732\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 6s 126us/sample - loss: 0.3088 - accuracy: 0.8863 - val_loss: 0.3300 - val_accuracy: 0.8842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13a3be410>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verificação dos resultados do modelo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "10000/10000 [==============================] - 0s 40us/sample - loss: 0.3224 - accuracy: 0.8811\n",
      "Model - 3 layers - test loss: 32.237203629016875\n",
      "Model - 3 layers - test accuracy: 88.10999989509583\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Model - 3 layers - test loss:\", test_loss * 100)\n",
    "print(\"Model - 3 layers - test accuracy:\", test_acc * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------\n",
    "## Redução de Dimensionalidade Usando Principal component analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definição do número de componentes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Construção dos novos datasets de treino e de teste com dimensões reduzidas usando o PCA:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_r = pca.fit(train_images).transform(train_images)\n",
    "test_images_r = pca.fit(test_images).transform(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alteração do tipo dos dados de numpy array para pandas dataframe:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_r = pd.DataFrame(data=train_images_r)\n",
    "test_images_r= pd.DataFrame(data=test_images_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definição da estrutura do modelo por meio do Keras Sequential que receberá os dados com dimensões reduzidas pelo PCA:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 9,866\n",
      "Trainable params: 9,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_r = keras.Sequential([\n",
    "    keras.layers.Dense(64,activation=tf.nn.relu,input_dim=(3)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_r.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compilação do modelo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_r.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Treino do modelo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 3s 59us/sample - loss: 0.9848 - accuracy: 0.5941 - val_loss: 0.9172 - val_accuracy: 0.6154\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 3s 54us/sample - loss: 0.8961 - accuracy: 0.6240 - val_loss: 0.8983 - val_accuracy: 0.6109\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 2s 50us/sample - loss: 0.8787 - accuracy: 0.6352 - val_loss: 0.8878 - val_accuracy: 0.6264\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 2s 49us/sample - loss: 0.8705 - accuracy: 0.6371 - val_loss: 0.8760 - val_accuracy: 0.6387\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 2s 51us/sample - loss: 0.8628 - accuracy: 0.6416 - val_loss: 0.8657 - val_accuracy: 0.6405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13a5e8c90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_r.fit(train_images_r, train_labels, epochs=5, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verificação dos resultados do modelo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "10000/10000 [==============================] - 0s 19us/sample - loss: 0.8679 - accuracy: 0.6325\n",
      "Model - 3 layers - test loss: 86.78787710189819\n",
      "Model - 3 layers - test accuracy: 63.24999928474426\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_r.evaluate(test_images_r, test_labels)\n",
    "print(\"Model - 3 layers - test loss:\", test_loss * 100)\n",
    "print(\"Model - 3 layers - test accuracy:\", test_acc * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------\n",
    "\n",
    "## Redução de Dimensionalidade Usando Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the size of our encoded representations\n",
    "encoding_dim = 2\n",
    "input_img = Input(shape=(784,))\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "encoder = Model(input_img, encoded)\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "autoencoder = Model(input_img, decoded)\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVER troque o 'adadelta' pelo 'adam'\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.4339 - val_loss: 0.4070\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.4003 - val_loss: 0.3934\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.3897 - val_loss: 0.3848\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 0.3823 - val_loss: 0.3787\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.3784 - val_loss: 0.3765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x13a8d0b10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(train_images, train_images,\n",
    "                epochs=5,\n",
    "                shuffle=True,\n",
    "                validation_data=(test_images, test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs_train = encoder.predict(train_images)\n",
    "encoded_imgs_test = encoder.predict(test_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_a = pd.DataFrame(data=encoded_imgs_train)\n",
    "test_images_a =pd.DataFrame(data=encoded_imgs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 64)                192       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 9,802\n",
      "Trainable params: 9,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_r = keras.Sequential([\n",
    "    keras.layers.Dense(64,activation=tf.nn.relu,input_dim=(2)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_r.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_r.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 3s 56us/sample - loss: 1.2776 - accuracy: 0.4770 - val_loss: 1.1652 - val_accuracy: 0.5298\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 3s 59us/sample - loss: 1.1591 - accuracy: 0.5273 - val_loss: 1.1587 - val_accuracy: 0.5247\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 3s 54us/sample - loss: 1.1415 - accuracy: 0.5338 - val_loss: 1.1358 - val_accuracy: 0.5401\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 3s 57us/sample - loss: 1.1327 - accuracy: 0.5375 - val_loss: 1.1280 - val_accuracy: 0.5381\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 2s 51us/sample - loss: 1.1292 - accuracy: 0.5388 - val_loss: 1.1270 - val_accuracy: 0.5425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13b538b90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_r.fit(train_images_a, train_labels, epochs=5, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 1.1251 - accuracy: 0.5438\n",
      "Model - 3 layers - test loss: 112.50503034591675\n",
      "Model - 3 layers - test accuracy: 54.37999963760376\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_r.evaluate(test_images_a, test_labels)\n",
    "print(\"Model - 3 layers - test loss:\", test_loss * 100)\n",
    "print(\"Model - 3 layers - test accuracy:\", test_acc * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------\n",
    "\n",
    "## Clustering com K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optamos pela utilização das imagens reduzidas por meio do PCA, já que obtiveram os melhores resultados de predição na rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_k = train_images_r\n",
    "test_images_k = test_images_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=10, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmean_model = KMeans(n_clusters=10)\n",
    "kmean_model.fit(train_images_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.27051092, -0.13563267,  1.32175529],\n",
       "       [ 5.22021128, -2.52884828, -1.09440373],\n",
       "       [ 7.09581384,  2.84302316,  1.54863414],\n",
       "       [ 1.04541615, -4.99358442, -1.63890707],\n",
       "       [-1.46687273,  4.85195766, -4.08896511],\n",
       "       [-0.58298877, -0.3012933 ,  1.95696813],\n",
       "       [ 3.62148213,  1.29958684,  2.02530586],\n",
       "       [-2.42214801, -3.87270357,  0.43116225],\n",
       "       [ 1.26143436,  5.40593945, -0.41681487],\n",
       "       [-4.61510826,  2.87519023, -0.75452347]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmean_model.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "## Clustering com o DBScan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
