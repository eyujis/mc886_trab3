{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "import sklearn as sk\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processamento dos dados\n",
    "**Carregando os dados de treino e teste:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = pd.read_csv('../fashion-mnist_train.csv')\n",
    "test_images = pd.read_csv('../fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separando as labels do conjuntos:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=train_images.loc[:, ['label']]\n",
    "train_images=train_images.drop(['label'], axis=1)\n",
    "test_labels=test_images.loc[:, ['label']]\n",
    "test_images=test_images.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalizando os data-sets:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "## Construção do modelo base\n",
    "**Esta rede será utilizada posteriomente para comparações entre os modelos de dimensionalidade reduzida utilizando PCA e autoencoder.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definição da estrutura do modelo por meio do Keras Sequential:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 59,850\n",
      "Trainable params: 59,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64,activation=tf.nn.relu,input_dim=(784)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compilação do modelo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Treino do modelo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.5242 - accuracy: 0.8120 - val_loss: 0.4055 - val_accuracy: 0.8550\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 5s 111us/sample - loss: 0.3852 - accuracy: 0.8590 - val_loss: 0.3714 - val_accuracy: 0.8681\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 5s 111us/sample - loss: 0.3495 - accuracy: 0.8715 - val_loss: 0.3658 - val_accuracy: 0.8686\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 5s 110us/sample - loss: 0.3259 - accuracy: 0.8798 - val_loss: 0.3730 - val_accuracy: 0.8656\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 5s 111us/sample - loss: 0.3079 - accuracy: 0.8864 - val_loss: 0.3680 - val_accuracy: 0.8708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a34542358>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verificação dos resultados do modelo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "10000/10000 [==============================] - 1s 66us/sample - loss: 0.3503 - accuracy: 0.8727\n",
      "Model - 3 layers - test loss: 35.0270946097374\n",
      "Model - 3 layers - test accuracy: 87.26999759674072\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Model - 3 layers - test loss:\", test_loss * 100)\n",
    "print(\"Model - 3 layers - test accuracy:\", test_acc * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------\n",
    "## Redução de Dimensionalidade Usando Principal component analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definição do número de componentes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Construção dos novos datasets de treino e de teste com dimensões reduzidas usando o PCA:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       pixel1  pixel2  pixel3    pixel4    pixel5  pixel6  pixel7    pixel8  \\\n",
      "0         0.0     0.0     0.0  0.000000  0.000000     0.0     0.0  0.000000   \n",
      "1         0.0     0.0     0.0  0.000000  0.000000     0.0     0.0  0.000000   \n",
      "2         0.0     0.0     0.0  0.000000  0.000000     0.0     0.0  0.019608   \n",
      "3         0.0     0.0     0.0  0.003922  0.007843     0.0     0.0  0.000000   \n",
      "4         0.0     0.0     0.0  0.000000  0.000000     0.0     0.0  0.000000   \n",
      "...       ...     ...     ...       ...       ...     ...     ...       ...   \n",
      "59995     0.0     0.0     0.0  0.000000  0.000000     0.0     0.0  0.000000   \n",
      "59996     0.0     0.0     0.0  0.000000  0.000000     0.0     0.0  0.000000   \n",
      "59997     0.0     0.0     0.0  0.000000  0.000000     0.0     0.0  0.000000   \n",
      "59998     0.0     0.0     0.0  0.000000  0.000000     0.0     0.0  0.000000   \n",
      "59999     0.0     0.0     0.0  0.000000  0.000000     0.0     0.0  0.000000   \n",
      "\n",
      "       pixel9  pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
      "0         0.0      0.0  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "1         0.0      0.0  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "2         0.0      0.0  ...  0.000000  0.000000  0.000000  0.117647  0.168627   \n",
      "3         0.0      0.0  ...  0.011765  0.000000  0.000000  0.000000  0.000000   \n",
      "4         0.0      0.0  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "...       ...      ...  ...       ...       ...       ...       ...       ...   \n",
      "59995     0.0      0.0  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "59996     0.0      0.0  ...  0.286275  0.000000  0.000000  0.000000  0.000000   \n",
      "59997     0.0      0.0  ...  0.627451  0.635294  0.639216  0.529412  0.368627   \n",
      "59998     0.0      0.0  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "59999     0.0      0.0  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
      "0      0.000000       0.0       0.0       0.0       0.0  \n",
      "1      0.000000       0.0       0.0       0.0       0.0  \n",
      "2      0.000000       0.0       0.0       0.0       0.0  \n",
      "3      0.003922       0.0       0.0       0.0       0.0  \n",
      "4      0.000000       0.0       0.0       0.0       0.0  \n",
      "...         ...       ...       ...       ...       ...  \n",
      "59995  0.000000       0.0       0.0       0.0       0.0  \n",
      "59996  0.000000       0.0       0.0       0.0       0.0  \n",
      "59997  0.000000       0.0       0.0       0.0       0.0  \n",
      "59998  0.000000       0.0       0.0       0.0       0.0  \n",
      "59999  0.000000       0.0       0.0       0.0       0.0  \n",
      "\n",
      "[60000 rows x 784 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_images)\n",
    "train_images_r = pca.fit(train_images).transform(train_images)\n",
    "test_images_r = pca.fit(test_images).transform(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alteração do tipo dos dados de numpy array para pandas dataframe:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0         1         2\n",
      "0      3.686333  4.960529 -0.051232\n",
      "1     -4.376434  3.861059 -1.949433\n",
      "2      7.265152  1.568757  2.315238\n",
      "3      3.227788 -2.325256 -0.649302\n",
      "4      4.146373 -4.039080 -1.515247\n",
      "...         ...       ...       ...\n",
      "59995  0.017613  5.188697 -5.057010\n",
      "59996 -3.115212 -5.211554 -0.104906\n",
      "59997  2.181650  0.451775 -0.556464\n",
      "59998  1.470069  6.063398 -0.624757\n",
      "59999 -3.571693  4.771146 -0.266293\n",
      "\n",
      "[60000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "train_images_r = pd.DataFrame(data=train_images_r)\n",
    "test_images_r= pd.DataFrame(data=test_images_r)\n",
    "print(train_images_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definição da estrutura do modelo por meio do Keras Sequential que receberá os dados com dimensões reduzidas pelo PCA:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 9,866\n",
      "Trainable params: 9,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_r = keras.Sequential([\n",
    "    keras.layers.Dense(64,activation=tf.nn.relu,input_dim=(3)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_r.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compilação do modelo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_r.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Treino do modelo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 3s 64us/sample - loss: 0.9808 - accuracy: 0.5942 - val_loss: 0.9134 - val_accuracy: 0.6148\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 3s 58us/sample - loss: 0.8971 - accuracy: 0.6259 - val_loss: 0.8862 - val_accuracy: 0.6363\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 3s 61us/sample - loss: 0.8777 - accuracy: 0.6359 - val_loss: 0.8938 - val_accuracy: 0.6146\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 3s 59us/sample - loss: 0.8686 - accuracy: 0.6399 - val_loss: 0.8662 - val_accuracy: 0.6426\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 3s 59us/sample - loss: 0.8621 - accuracy: 0.6428 - val_loss: 0.8705 - val_accuracy: 0.6317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3467d160>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_r.fit(train_images_r, train_labels, epochs=5, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verificação dos resultados do modelo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "10000/10000 [==============================] - 0s 37us/sample - loss: 0.8880 - accuracy: 0.6221\n",
      "Model - 3 layers - test loss: 88.79879961013793\n",
      "Model - 3 layers - test accuracy: 62.209999561309814\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_r.evaluate(test_images_r, test_labels)\n",
    "print(\"Model - 3 layers - test loss:\", test_loss * 100)\n",
    "print(\"Model - 3 layers - test accuracy:\", test_acc * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------\n",
    "\n",
    "## Redução de Dimensionalidade Usando Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the size of our encoded representations\n",
    "encoding_dim = 2\n",
    "input_img = Input(shape=(784,))\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "encoder = Model(input_img, encoded)\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "autoencoder = Model(input_img, decoded)\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVER troque o 'adadelta' pelo 'adam'\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 0.4379 - val_loss: 0.4076\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.4009 - val_loss: 0.3941\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.3904 - val_loss: 0.3853\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.3830 - val_loss: 0.3793\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.3788 - val_loss: 0.3768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a37232320>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(train_images, train_images,epochs=5,shuffle=True,validation_data=(test_images, test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs_train = encoder.predict(train_images)\n",
    "encoded_imgs_test = encoder.predict(test_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_a = pd.DataFrame(data=encoded_imgs_train)\n",
    "test_images_a =pd.DataFrame(data=encoded_imgs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 64)                192       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 9,802\n",
      "Trainable params: 9,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_r = keras.Sequential([\n",
    "    keras.layers.Dense(64,activation=tf.nn.relu,input_dim=(2)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_r.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_r.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 3s 65us/sample - loss: 1.2896 - accuracy: 0.4697 - val_loss: 1.1981 - val_accuracy: 0.4937\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 3s 62us/sample - loss: 1.1674 - accuracy: 0.5240 - val_loss: 1.1428 - val_accuracy: 0.5356\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 3s 69us/sample - loss: 1.1480 - accuracy: 0.5327 - val_loss: 1.1494 - val_accuracy: 0.5334\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 3s 61us/sample - loss: 1.1393 - accuracy: 0.5378 - val_loss: 1.1460 - val_accuracy: 0.5337\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 3s 68us/sample - loss: 1.1334 - accuracy: 0.5388 - val_loss: 1.1256 - val_accuracy: 0.5471ss: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a36baf438>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_r.fit(train_images_a, train_labels, epochs=5, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "10000/10000 [==============================] - 0s 34us/sample - loss: 1.1272 - accuracy: 0.5456\n",
      "Model - 3 layers - test loss: 112.7247098350525\n",
      "Model - 3 layers - test accuracy: 54.55999970436096\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_r.evaluate(test_images_a, test_labels)\n",
    "print(\"Model - 3 layers - test loss:\", test_loss * 100)\n",
    "print(\"Model - 3 layers - test accuracy:\", test_acc * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------\n",
    "\n",
    "## Clustering com K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optamos pela utilização das imagens reduzidas por meio do PCA, já que obtiveram por meio deste modelo os melhores resultados de predição na rede neural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0         1         2\n",
      "0      3.686333  4.960529 -0.051232\n",
      "1     -4.376434  3.861059 -1.949433\n",
      "2      7.265152  1.568757  2.315238\n",
      "3      3.227788 -2.325256 -0.649302\n",
      "4      4.146373 -4.039080 -1.515247\n",
      "...         ...       ...       ...\n",
      "59995  0.017613  5.188697 -5.057010\n",
      "59996 -3.115212 -5.211554 -0.104906\n",
      "59997  2.181650  0.451775 -0.556464\n",
      "59998  1.470069  6.063398 -0.624757\n",
      "59999 -3.571693  4.771146 -0.266293\n",
      "\n",
      "[60000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "train_images_k = train_images_r\n",
    "test_images_k = test_images_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmean_model = KMeans(n_clusters=10, random_state=10)\n",
    "y_km = kmean_model.fit(train_images_k)\n",
    "labels = kmean_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.47795544,  4.85036523, -4.08379711],\n",
       "       [ 5.22431048, -2.52399581, -1.09236905],\n",
       "       [-6.27010392, -0.1455124 ,  1.32735672],\n",
       "       [ 7.10153782,  2.8490961 ,  1.54810651],\n",
       "       [ 1.0550687 , -4.99256822, -1.64092359],\n",
       "       [ 1.26163488,  5.40100598, -0.42115934],\n",
       "       [-0.57978915, -0.29839877,  1.95840623],\n",
       "       [-2.41034674, -3.87926138,  0.42164997],\n",
       "       [ 3.63451199,  1.3027061 ,  2.02472775],\n",
       "       [-4.62487752,  2.8643774 , -0.74438809]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_centroids = kmean_model.cluster_centers_\n",
    "cluster_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#silhouette_avg = silhouette_score(X = train_images_k, labels = train_labels.values.ravel(), random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_avg = silhouette_score(X = train_images_k, labels = train_labels.values.ravel(), random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics.homogeneity_score(train_labels.values.ravel(), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45694727123110823"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.v_measure_score(train_labels.values.ravel(), labels, beta=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "## Clustering com o DBScan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.68633325  4.96052901 -0.05123188]\n",
      " [-4.37643435  3.86105868 -1.94943298]\n",
      " [ 7.26515192  1.56875666  2.31523852]\n",
      " ...\n",
      " [ 2.18165029  0.45177534 -0.55646427]\n",
      " [ 1.47006912  6.06339785 -0.62475691]\n",
      " [-3.57169302  4.77114625 -0.2662927 ]]\n",
      "[ 0  0  0 ... -1  0 -1]\n",
      "Estimated number of clusters: 22\n",
      "Estimated number of noise points: 4960\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_images_dbscan = train_images_r\n",
    "test_images_dbscan = test_images_r\n",
    "\n",
    "print(train_images_dbscan)\n",
    "\n",
    "\n",
    "neigh = NearestNeighbors(n_neighbors=10)\n",
    "nbrs = neigh.fit(train_images_dbscan)\n",
    "distances, indices = nbrs.kneighbors(train_images_dbscan)\n",
    "\n",
    "distances = np.sort(distances, axis=0)\n",
    "distances = distances[:,1]\n",
    "plt.plot(distances)\n",
    "\n",
    "\n",
    "db = DBSCAN(eps=0.38, min_samples=10).fit(train_images_dbscan)\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "print(labels)\n",
    "print(len(labels))\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<numpy.vectorize object at 0x1a38d10588>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'c' argument has 4 elements, which is not acceptable for use with 'x' with size 60000, 'y' with size 60000.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36m_parse_scatter_color_args\u001b[0;34m(c, edgecolors, kwargs, xshape, yshape, get_next_color_func)\u001b[0m\n\u001b[1;32m   4284\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Then is 'c' acceptable as PathCollection facecolors?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4285\u001b[0;31m                 \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4286\u001b[0m                 \u001b[0mn_elem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36mto_rgba_array\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36mto_rgba\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrgba\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Suppress exception chaining of cache lookup failure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_rgba_no_colorcycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36m_to_rgba_no_colorcycle\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGBA sequence should have length 3 or 4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: RGBA sequence should have length 3 or 4",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-6d5c88ef37ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images_dbscan\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_images_dbscan\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# for k, col in zip(unique_labels, colors):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[0mverts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medgecolors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2846\u001b[0m         plotnonfinite=plotnonfinite, **({\"data\": data} if data is not\n\u001b[0;32m-> 2847\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2848\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2849\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1601\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4452\u001b[0m             self._parse_scatter_color_args(\n\u001b[1;32m   4453\u001b[0m                 \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4454\u001b[0;31m                 get_next_color_func=self._get_patches_for_fill.get_next_color)\n\u001b[0m\u001b[1;32m   4455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4456\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mplotnonfinite\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36m_parse_scatter_color_args\u001b[0;34m(c, edgecolors, kwargs, xshape, yshape, get_next_color_func)\u001b[0m\n\u001b[1;32m   4296\u001b[0m                         \u001b[0;34m\"acceptable for use with 'x' with size {xs}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4297\u001b[0m                         \u001b[0;34m\"'y' with size {ys}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4298\u001b[0;31m                             \u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_elem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mysize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4299\u001b[0m                     )\n\u001b[1;32m   4300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'c' argument has 4 elements, which is not acceptable for use with 'x' with size 60000, 'y' with size 60000."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot result\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.gca(projection='3d')\n",
    "# ax.plot(train_images_dbscan[:20, 0], train_images_dbscan[:20, 1], train_images_dbscan[:20, 2], label='parametric curve')\n",
    "# ax.legend()\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# Black removed and is used for noise instead.\n",
    "unique_labels = set(labels)\n",
    "colors = [plt.cm.Spectral(each)\n",
    "          for each in np.linspace(0, 1, len(unique_labels))]\n",
    "\n",
    "vectorizer = np.vectorize(lambda x: colors[x % len(colors)])\n",
    "\n",
    "print(vectorizer)\n",
    "\n",
    "plt.scatter(train_images_dbscan[:,0], train_images_dbscan[:,1], c=vectorizer(labels))\n",
    "\n",
    "# for k, col in zip(unique_labels, colors):\n",
    "#     if k == -1:\n",
    "#         # Black used for noise.\n",
    "#         col = [0, 0, 0, 1]\n",
    "\n",
    "#     class_member_mask = (labels == k)\n",
    "\n",
    "#     xy = train_images_dbscan[class_member_mask & core_samples_mask]\n",
    "#     plt.plot(train_images_dbscan[:, 0], train_images_dbscan[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "#              markeredgecolor='k', markersize=14)\n",
    "\n",
    "#     xy = train_images_dbscan[class_member_mask & ~core_samples_mask]\n",
    "#     plt.plot(train_images_dbscan[:, 0], train_images_dbscan[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "#              markeredgecolor='k', markersize=6)\n",
    "\n",
    "# plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
