{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "import sklearn as sk\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processamento dos dados\n",
    "**Carregando os dados de treino e teste:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = pd.read_csv('fashion-mnist_train.csv')\n",
    "test_images = pd.read_csv('fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separando as labels do conjuntos:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=train_images.loc[:, ['label']]\n",
    "train_images=train_images.drop(['label'], axis=1)\n",
    "test_labels=test_images.loc[:, ['label']]\n",
    "test_images=test_images.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalizando os data-sets:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "## Construção do modelo base\n",
    "**Esta rede será utilizada posteriomente para comparações entre os modelos de dimensionalidade reduzida: PCA e autoencoder.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definição da estrutura do modelo por meio do Keras Sequential:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_96 (Dense)             (None, 120)               94200     \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 128)               15488     \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 110,978\n",
      "Trainable params: 110,978\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(120,activation=tf.nn.relu,input_dim=(784)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compilação do modelo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Treino do modelo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 6s 128us/sample - loss: 0.5134 - accuracy: 0.8154 - val_loss: 0.3987 - val_accuracy: 0.8574\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 0.3816 - accuracy: 0.8601 - val_loss: 0.3736 - val_accuracy: 0.8656\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 0.3433 - accuracy: 0.8731 - val_loss: 0.3535 - val_accuracy: 0.8732\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 5s 103us/sample - loss: 0.3194 - accuracy: 0.8836 - val_loss: 0.3503 - val_accuracy: 0.8737\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 5s 102us/sample - loss: 0.3000 - accuracy: 0.8882 - val_loss: 0.3496 - val_accuracy: 0.8728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1556e9990>"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verificação dos resultados do modelo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "10000/10000 [==============================] - 0s 40us/sample - loss: 0.3370 - accuracy: 0.8749\n",
      "Model - 3 layers - test loss: 33.69926504135132\n",
      "Model - 3 layers - test accuracy: 87.48999834060669\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Model - 3 layers - test loss:\", test_loss * 100)\n",
    "print(\"Model - 3 layers - test accuracy:\", test_acc * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------\n",
    "## Redução de Dimensionalidade Usando Principal component analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definição do número de componentes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Construção dos novos datasets de treino e de teste com dimensões reduzidas usando o PCA:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_r = pca.fit(train_images).transform(train_images)\n",
    "test_images_r = pca.fit(test_images).transform(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alteração do tipo dos dados de numpy array para pandas dataframe:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_r = pd.DataFrame(data=train_images_r)\n",
    "test_images_r= pd.DataFrame(data=test_images_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definição da estrutura do modelo por meio do Keras Sequential que receberá os dados com dimensões reduzidas pelo PCA:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_99 (Dense)             (None, 120)               480       \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 128)               15488     \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 17,258\n",
      "Trainable params: 17,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_r = keras.Sequential([\n",
    "    keras.layers.Dense(120,activation=tf.nn.relu,input_dim=(3)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_r.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compilação do modelo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_r.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Treino do modelo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 2s 47us/sample - loss: 0.9695 - accuracy: 0.5992 - val_loss: 0.9134 - val_accuracy: 0.6223\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 2s 44us/sample - loss: 0.8886 - accuracy: 0.6290 - val_loss: 0.8834 - val_accuracy: 0.6375\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 2s 49us/sample - loss: 0.8720 - accuracy: 0.6376 - val_loss: 0.8701 - val_accuracy: 0.6414\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 3s 52us/sample - loss: 0.8647 - accuracy: 0.6426 - val_loss: 0.8698 - val_accuracy: 0.6418\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 2s 52us/sample - loss: 0.8585 - accuracy: 0.6408 - val_loss: 0.8644 - val_accuracy: 0.6423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1582eacd0>"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_r.fit(train_images_r, train_labels, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verificação dos resultados do modelo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "10000/10000 [==============================] - 0s 21us/sample - loss: 0.8848 - accuracy: 0.6295\n",
      "Model - 3 layers - test loss: 88.47663967132569\n",
      "Model - 3 layers - test accuracy: 62.94999718666077\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_r.evaluate(test_images_r, test_labels)\n",
    "print(\"Model - 3 layers - test loss:\", test_loss * 100)\n",
    "print(\"Model - 3 layers - test accuracy:\", test_acc * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------\n",
    "\n",
    "## Redução de Dimensionalidade Usando Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the size of our encoded representations\n",
    "encoding_dim = 2\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(784,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(784, activation='softmax')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 1.8196 - val_loss: 1.7946\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 1.7815 - val_loss: 1.7830\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 1.7776 - val_loss: 1.7806\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 1.7758 - val_loss: 1.7792\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 1.7746 - val_loss: 1.7781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x158b2bf50>"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(train_images, train_images,\n",
    "                epochs=5,\n",
    "                shuffle=True,\n",
    "                validation_data=(test_images, test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs_train = encoder.predict(train_images)\n",
    "encoded_imgs_test = encoder.predict(test_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_a = pd.DataFrame(data=encoded_imgs_train)\n",
    "test_images_a =pd.DataFrame(data=encoded_imgs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_102 (Dense)            (None, 120)               360       \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 128)               15488     \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 17,138\n",
      "Trainable params: 17,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_r = keras.Sequential([\n",
    "    keras.layers.Dense(120,activation=tf.nn.relu,input_dim=(2)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_r.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_r.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 3s 64us/sample - loss: 1.4052 - accuracy: 0.4149 - val_loss: 1.3210 - val_accuracy: 0.4627\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 3s 67us/sample - loss: 1.3117 - accuracy: 0.4607 - val_loss: 1.3068 - val_accuracy: 0.4638\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 3s 58us/sample - loss: 1.3013 - accuracy: 0.4680 - val_loss: 1.3041 - val_accuracy: 0.4663\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 3s 57us/sample - loss: 1.2940 - accuracy: 0.4714 - val_loss: 1.3047 - val_accuracy: 0.4653\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 3s 53us/sample - loss: 1.2888 - accuracy: 0.4720 - val_loss: 1.2948 - val_accuracy: 0.4694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1599a0e90>"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_r.fit(train_images_a, train_labels, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "10000/10000 [==============================] - 0s 34us/sample - loss: 1.2895 - accuracy: 0.4767\n",
      "Model - 3 layers - test loss: 128.95283668518067\n",
      "Model - 3 layers - test accuracy: 47.67000079154968\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_r.evaluate(test_images_a, test_labels)\n",
    "print(\"Model - 3 layers - test loss:\", test_loss * 100)\n",
    "print(\"Model - 3 layers - test accuracy:\", test_acc * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
